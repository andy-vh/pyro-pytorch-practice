{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--train-window TRAIN_WINDOW]\n",
      "                             [--test-window TEST_WINDOW] [--stride STRIDE]\n",
      "                             [-n NUM_STEPS] [-lr LEARNING_RATE] [--dct]\n",
      "                             [--num-samples NUM_SAMPLES]\n",
      "                             [--log-every LOG_EVERY] [--seed SEED]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/andy/.local/share/jupyter/runtime/kernel-650e7b12-5bd3-4f02-8858-feca0779605c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/anaconda3/envs/pyro/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.examples.bart import load_bart_od\n",
    "from pyro.contrib.forecast import ForecastingModel, backtest\n",
    "from pyro.ops.tensor_utils import periodic_cumsum, periodic_repeat\n",
    "\n",
    "logging.getLogger(\"pyro\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"pyro\").handlers[0].setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def preprocess(args):\n",
    "    \"\"\"\n",
    "    Extract a tensor of (arrivals,departures) to Embarcadero station.\n",
    "    \"\"\"\n",
    "    print(\"Loading data\")\n",
    "    dataset = load_bart_od()\n",
    "\n",
    "    # The full dataset has all station->station ridership counts for all of 50\n",
    "    # train stations. In this simple example we will model only the aggretate\n",
    "    # counts to and from a single station, Embarcadero.\n",
    "    i = dataset[\"stations\"].index(\"EMBR\")\n",
    "    arrivals = dataset[\"counts\"][:, :, i].sum(-1)\n",
    "    departures = dataset[\"counts\"][:, i, :].sum(-1)\n",
    "    data = torch.stack([arrivals, departures], dim=-1)\n",
    "\n",
    "    # This simple example uses no covariates, so we will construct a\n",
    "    # zero-element tensor of the correct length as empty covariates.\n",
    "    covariates = torch.zeros(len(data), 0)\n",
    "\n",
    "    return data, covariates\n",
    "\n",
    "\n",
    "# We define a model by subclassing the ForecastingModel class and implementing\n",
    "# a single .model() method.\n",
    "class Model(ForecastingModel):\n",
    "    # The .model() method inputs two tensors: a fake tensor zero_data that is\n",
    "    # the same size and dtype as the real data (but of course the generative\n",
    "    # model shouldn't depend on the value of the data it generates!), and a\n",
    "    # tensor of covariates. Our simple model depends on no covariates, so we\n",
    "    # simply pass in an empty tensor (see  the preprocess() function above).\n",
    "    def model(self, zero_data, covariates):\n",
    "        period = 24 * 7\n",
    "        duration, dim = zero_data.shape[-2:]\n",
    "        assert dim == 2  # Data is bivariate: (arrivals, departures).\n",
    "\n",
    "        # Sample global parameters.\n",
    "        noise_scale = pyro.sample(\"noise_scale\",\n",
    "                                  dist.LogNormal(torch.full((dim,), -3), 1).to_event(1))\n",
    "        assert noise_scale.shape[-1:] == (dim,)\n",
    "        trans_timescale = pyro.sample(\"trans_timescale\",\n",
    "                                      dist.LogNormal(torch.zeros(dim), 1).to_event(1))\n",
    "        assert trans_timescale.shape[-1:] == (dim,)\n",
    "\n",
    "        trans_loc = pyro.sample(\"trans_loc\", dist.Cauchy(0, 1 / period))\n",
    "        trans_loc = trans_loc.unsqueeze(-1).expand(trans_loc.shape + (dim,))\n",
    "        assert trans_loc.shape[-1:] == (dim,)\n",
    "        trans_scale = pyro.sample(\"trans_scale\",\n",
    "                                  dist.LogNormal(torch.zeros(dim), 0.1).to_event(1))\n",
    "        trans_corr = pyro.sample(\"trans_corr\",\n",
    "                                 dist.LKJCorrCholesky(dim, torch.ones(())))\n",
    "        trans_scale_tril = trans_scale.unsqueeze(-1) * trans_corr\n",
    "        assert trans_scale_tril.shape[-2:] == (dim, dim)\n",
    "\n",
    "        obs_scale = pyro.sample(\"obs_scale\",\n",
    "                                dist.LogNormal(torch.zeros(dim), 0.1).to_event(1))\n",
    "        obs_corr = pyro.sample(\"obs_corr\",\n",
    "                               dist.LKJCorrCholesky(dim, torch.ones(())))\n",
    "        obs_scale_tril = obs_scale.unsqueeze(-1) * obs_corr\n",
    "        assert obs_scale_tril.shape[-2:] == (dim, dim)\n",
    "\n",
    "        # Note the initial seasonality should be sampled in a plate with the\n",
    "        # same dim as the time_plate, dim=-1. That way we can repeat the dim\n",
    "        # below using periodic_repeat().\n",
    "        with pyro.plate(\"season_plate\", period,  dim=-1):\n",
    "            season_init = pyro.sample(\"season_init\",\n",
    "                                      dist.Normal(torch.zeros(dim), 1).to_event(1))\n",
    "            assert season_init.shape[-2:] == (period, dim)\n",
    "\n",
    "        # Sample independent noise at each time step.\n",
    "        with self.time_plate:\n",
    "            season_noise = pyro.sample(\"season_noise\",\n",
    "                                       dist.Normal(0, noise_scale).to_event(1))\n",
    "            assert season_noise.shape[-2:] == (duration, dim)\n",
    "\n",
    "        # Construct a prediction. This prediction has an exactly repeated\n",
    "        # seasonal part plus slow seasonal drift. We use two deterministic,\n",
    "        # linear functions to transform our diagonal Normal noise to nontrivial\n",
    "        # samples from a Gaussian process.\n",
    "        prediction = (periodic_repeat(season_init, duration, dim=-2) +\n",
    "                      periodic_cumsum(season_noise, period, dim=-2))\n",
    "        assert prediction.shape[-2:] == (duration, dim)\n",
    "\n",
    "        # Construct a joint noise model. This model is a GaussianHMM, whose\n",
    "        # .rsample() and .log_prob() methods are parallelized over time; this\n",
    "        # this entire model is parallelized over time.\n",
    "        init_dist = dist.Normal(torch.zeros(dim), 100).to_event(1)\n",
    "        trans_mat = trans_timescale.neg().exp().diag_embed()\n",
    "        trans_dist = dist.MultivariateNormal(trans_loc, scale_tril=trans_scale_tril)\n",
    "        obs_mat = torch.eye(dim)\n",
    "        obs_dist = dist.MultivariateNormal(torch.zeros(dim), scale_tril=obs_scale_tril)\n",
    "        noise_model = dist.GaussianHMM(init_dist, trans_mat, trans_dist, obs_mat, obs_dist,\n",
    "                                       duration=duration)\n",
    "        assert noise_model.event_shape == (duration, dim)\n",
    "\n",
    "        # The final statement registers our noise model and prediction.\n",
    "        self.predict(noise_model, prediction)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    pyro.enable_validation(__debug__)\n",
    "    data, covariates = preprocess(args)\n",
    "\n",
    "    # We will model positive count data by log1p-transforming it into real\n",
    "    # valued data.  But since we want to evaluate back in the count domain, we\n",
    "    # will also define a transform to apply during evaluation, transforming\n",
    "    # from real back to count-valued data. Truth is mapped by the log1p()\n",
    "    # inverse expm1(), but the prediction will be sampled from a Poisson\n",
    "    # distribution.\n",
    "    data = data.log1p()\n",
    "\n",
    "    def transform(pred, truth):\n",
    "        pred = torch.poisson(pred.clamp(min=1e-4).expm1())\n",
    "        truth = truth.expm1()\n",
    "        return pred, truth\n",
    "\n",
    "    # The backtest() function automatically trains and evaluates our model on\n",
    "    # different windows of data.\n",
    "    forecaster_options = {\n",
    "        \"num_steps\": args.num_steps,\n",
    "        \"learning_rate\": args.learning_rate,\n",
    "        \"log_every\": args.log_every,\n",
    "        \"dct_gradients\": args.dct,\n",
    "    }\n",
    "    metrics = backtest(data, covariates, Model,\n",
    "                       train_window=args.train_window,\n",
    "                       test_window=args.test_window,\n",
    "                       stride=args.stride,\n",
    "                       num_samples=args.num_samples,\n",
    "                       forecaster_options=forecaster_options)\n",
    "\n",
    "    for name in [\"mae\", \"rmse\", \"crps\"]:\n",
    "        values = [m[name] for m in metrics]\n",
    "        mean = np.mean(values)\n",
    "        std = np.std(values)\n",
    "        print(\"{} = {:0.3g} +- {:0.3g}\".format(name, mean, std))\n",
    "    return metrics\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    assert pyro.__version__.startswith('1.3.0')\n",
    "    parser = argparse.ArgumentParser(description=\"Bart Ridership Forecasting Example\")\n",
    "    parser.add_argument(\"--train-window\", default=2160, type=int)\n",
    "    parser.add_argument(\"--test-window\", default=336, type=int)\n",
    "    parser.add_argument(\"--stride\", default=168, type=int)\n",
    "    parser.add_argument(\"-n\", \"--num-steps\", default=501, type=int)\n",
    "    parser.add_argument(\"-lr\", \"--learning-rate\", default=0.05, type=float)\n",
    "    parser.add_argument(\"--dct\", action=\"store_true\")\n",
    "    parser.add_argument(\"--num-samples\", default=100, type=int)\n",
    "    parser.add_argument(\"--log-every\", default=50, type=int)\n",
    "    parser.add_argument(\"--seed\", default=1234567890, type=int)\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArgumentParser(prog='ipykernel_launcher.py', usage=None, description='Bart Ridership Forecasting Example', formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro",
   "language": "python",
   "name": "pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
