{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampled from [tds post](https://towardsdatascience.com/linear-regression-with-pytorch-eb6dedead817)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# create dummy data for training\n",
    "x_values = [i for i in range(11)]\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDim = 1        # takes variable 'x' \n",
    "outputDim = 1       # takes variable 'y'\n",
    "learningRate = 0.01 \n",
    "epochs = 100\n",
    "\n",
    "model = linearRegression(inputDim, outputDim)\n",
    "##### For GPU #######\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(302.1089, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 0, loss 302.10894775390625\n",
      "tensor(24.9094, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 1, loss 24.909378051757812\n",
      "tensor(2.2961, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 2, loss 2.2961018085479736\n",
      "tensor(0.4487, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 3, loss 0.4486556649208069\n",
      "tensor(0.2950, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 4, loss 0.2950472831726074\n",
      "tensor(0.2796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 5, loss 0.27963197231292725\n",
      "tensor(0.2755, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 6, loss 0.2755207121372223\n",
      "tensor(0.2724, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 7, loss 0.2723632752895355\n",
      "tensor(0.2693, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 8, loss 0.2693152129650116\n",
      "tensor(0.2663, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 9, loss 0.2663072645664215\n",
      "tensor(0.2633, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 10, loss 0.2633334994316101\n",
      "tensor(0.2604, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 11, loss 0.2603928744792938\n",
      "tensor(0.2575, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 12, loss 0.2574850618839264\n",
      "tensor(0.2546, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 13, loss 0.2546098232269287\n",
      "tensor(0.2518, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 14, loss 0.2517666816711426\n",
      "tensor(0.2490, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 15, loss 0.24895523488521576\n",
      "tensor(0.2462, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 16, loss 0.24617525935173035\n",
      "tensor(0.2434, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 17, loss 0.2434261590242386\n",
      "tensor(0.2407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 18, loss 0.24070784449577332\n",
      "tensor(0.2380, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 19, loss 0.2380199432373047\n",
      "tensor(0.2354, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 20, loss 0.23536190390586853\n",
      "tensor(0.2327, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 21, loss 0.23273372650146484\n",
      "tensor(0.2301, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 22, loss 0.2301347553730011\n",
      "tensor(0.2276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 23, loss 0.22756490111351013\n",
      "tensor(0.2250, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 24, loss 0.22502367198467255\n",
      "tensor(0.2225, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 25, loss 0.2225109040737152\n",
      "tensor(0.2200, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 26, loss 0.2200261950492859\n",
      "tensor(0.2176, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 27, loss 0.2175692468881607\n",
      "tensor(0.2151, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 28, loss 0.21513965725898743\n",
      "tensor(0.2127, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 29, loss 0.21273712813854218\n",
      "tensor(0.2104, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 30, loss 0.21036165952682495\n",
      "tensor(0.2080, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 31, loss 0.20801250636577606\n",
      "tensor(0.2057, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 32, loss 0.20568963885307312\n",
      "tensor(0.2034, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 33, loss 0.20339269936084747\n",
      "tensor(0.2011, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 34, loss 0.20112156867980957\n",
      "tensor(0.1989, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 35, loss 0.19887565076351166\n",
      "tensor(0.1967, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 36, loss 0.19665488600730896\n",
      "tensor(0.1945, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 37, loss 0.1944587528705597\n",
      "tensor(0.1923, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 38, loss 0.19228725135326385\n",
      "tensor(0.1901, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 39, loss 0.1901400089263916\n",
      "tensor(0.1880, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 40, loss 0.18801681697368622\n",
      "tensor(0.1859, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 41, loss 0.1859172284603119\n",
      "tensor(0.1838, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 42, loss 0.18384110927581787\n",
      "tensor(0.1818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 43, loss 0.1817881017923355\n",
      "tensor(0.1798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 44, loss 0.179758220911026\n",
      "tensor(0.1778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 45, loss 0.17775088548660278\n",
      "tensor(0.1758, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 46, loss 0.1757659614086151\n",
      "tensor(0.1738, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 47, loss 0.17380322515964508\n",
      "tensor(0.1719, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 48, loss 0.1718624085187912\n",
      "tensor(0.1699, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 49, loss 0.1699432134628296\n",
      "tensor(0.1680, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 50, loss 0.16804540157318115\n",
      "tensor(0.1662, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 51, loss 0.1661689132452011\n",
      "tensor(0.1643, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 52, loss 0.16431336104869843\n",
      "tensor(0.1625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 53, loss 0.1624785214662552\n",
      "tensor(0.1607, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 54, loss 0.16066420078277588\n",
      "tensor(0.1589, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 55, loss 0.15887001156806946\n",
      "tensor(0.1571, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 56, loss 0.15709593892097473\n",
      "tensor(0.1553, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 57, loss 0.15534161031246185\n",
      "tensor(0.1536, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 58, loss 0.15360701084136963\n",
      "tensor(0.1519, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 59, loss 0.1518915891647339\n",
      "tensor(0.1502, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 60, loss 0.15019555389881134\n",
      "tensor(0.1485, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 61, loss 0.14851829409599304\n",
      "tensor(0.1469, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 62, loss 0.14685992896556854\n",
      "tensor(0.1452, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 63, loss 0.14521999657154083\n",
      "tensor(0.1436, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 64, loss 0.14359819889068604\n",
      "tensor(0.1420, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 65, loss 0.14199477434158325\n",
      "tensor(0.1404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 66, loss 0.14040905237197876\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 67, loss 0.13884109258651733\n",
      "tensor(0.1373, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 68, loss 0.13729074597358704\n",
      "tensor(0.1358, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 69, loss 0.13575762510299683\n",
      "tensor(0.1342, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 70, loss 0.13424152135849\n",
      "tensor(0.1327, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 71, loss 0.13274259865283966\n",
      "tensor(0.1313, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 72, loss 0.13126018643379211\n",
      "tensor(0.1298, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 73, loss 0.12979444861412048\n",
      "tensor(0.1283, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 74, loss 0.12834513187408447\n",
      "tensor(0.1269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 75, loss 0.12691189348697662\n",
      "tensor(0.1255, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 76, loss 0.12549461424350739\n",
      "tensor(0.1241, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 77, loss 0.12409331649541855\n",
      "tensor(0.1227, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 78, loss 0.12270764261484146\n",
      "tensor(0.1213, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 79, loss 0.12133726477622986\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 80, loss 0.11998237669467926\n",
      "tensor(0.1186, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 81, loss 0.11864248663187027\n",
      "tensor(0.1173, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 82, loss 0.11731766164302826\n",
      "tensor(0.1160, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 83, loss 0.11600760370492935\n",
      "tensor(0.1147, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 84, loss 0.1147121787071228\n",
      "tensor(0.1134, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 85, loss 0.1134311780333519\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 86, loss 0.11216451227664948\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 87, loss 0.11091195791959763\n",
      "tensor(0.1097, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 88, loss 0.1096733957529068\n",
      "tensor(0.1084, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 89, loss 0.10844873636960983\n",
      "tensor(0.1072, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 90, loss 0.10723777860403061\n",
      "tensor(0.1060, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 91, loss 0.10604018718004227\n",
      "tensor(0.1049, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 92, loss 0.10485605895519257\n",
      "tensor(0.1037, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 93, loss 0.10368513315916061\n",
      "tensor(0.1025, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 94, loss 0.10252723097801208\n",
      "tensor(0.1014, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 95, loss 0.10138241946697235\n",
      "tensor(0.1003, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 96, loss 0.1002502366900444\n",
      "tensor(0.0991, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 97, loss 0.09913081675767899\n",
      "tensor(0.0980, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 98, loss 0.09802385419607162\n",
      "tensor(0.0969, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 99, loss 0.0969291627407074\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Converting inputs and labels to Variable\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
    "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
    "    else:\n",
    "        inputs = Variable(torch.from_numpy(x_train))\n",
    "        labels = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.42085457]\n",
      " [ 2.5042567 ]\n",
      " [ 4.587659  ]\n",
      " [ 6.671061  ]\n",
      " [ 8.754463  ]\n",
      " [10.837866  ]\n",
      " [12.9212675 ]\n",
      " [15.004669  ]\n",
      " [17.088072  ]\n",
      " [19.171474  ]\n",
      " [21.254875  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad(): # we don't need gradients in the testing phase\n",
    "    if torch.cuda.is_available():\n",
    "        predicted = model(Variable(torch.from_numpy(x_train).cuda())).cpu().data.numpy()\n",
    "    else:\n",
    "        predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "    print(predicted)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro",
   "language": "python",
   "name": "pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
